{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mimg\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from keras.models import Sequential, Model\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "220e143251f748113b4e6d964495cb1fb68e1778",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cache_dir = expanduser(join('~', '.keras'))\n",
    "if not exists(cache_dir):\n",
    "    makedirs(cache_dir)\n",
    "    \n",
    "# make the models sub-directory\n",
    "models_dir = join(cache_dir, 'models')\n",
    "if not exists(models_dir):\n",
    "    makedirs(models_dir)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "cache_dir = expanduser(join('~', '.keras'))\n",
    "if not exists(cache_dir):\n",
    "    makedirs(cache_dir)\n",
    "    \n",
    "# make the models sub-directory\n",
    "models_dir = join(cache_dir, 'models')\n",
    "if not exists(models_dir):\n",
    "    makedirs(models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "51e9dc4ea19c4d49108cf1beec2cd39d1fee4d85",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cp ../input/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5 ~/.keras/models/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4bb90f4267a9201672a825c47e26396e826c24c7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_path = Path('../input/flowers-recognition/flowers/')\n",
    "flowers_path = input_path / 'flowers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ad95be8a3e1a0045222caa53e56fb8bdcb7d2c62",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flower_types = os.listdir(flowers_path)\n",
    "print(\"Types of flowers found: \", len(flower_types))\n",
    "print(\"Categories of flowers: \", flower_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "38c5c21ddfa0958fb48d6e457543eaf75f2c3d6b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flowers = []\n",
    "\n",
    "for species in flower_types:\n",
    "    # Get all the file names\n",
    "    all_flowers = os.listdir(flowers_path / species)\n",
    "    # Add them to the list\n",
    "    for flower in all_flowers:\n",
    "        flowers.append((species, str(flowers_path /species) + '/' + flower))\n",
    "\n",
    "# Build a dataframe        \n",
    "flowers = pd.DataFrame(data=flowers, columns=['category', 'image'], index=None)\n",
    "flowers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3e08c9e370f0df41f44402746064169927b87e2c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Total number of flowers in the dataset: \", len(flowers))\n",
    "fl_count = flowers['category'].value_counts()\n",
    "print(\"Flowers in each category: \")\n",
    "print(fl_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "860f14d7f52d39c08b4234c54822ea9960101102",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot(x=fl_count.index, y=fl_count.values)\n",
    "plt.title(\"Flowers count for each category\", fontsize=16)\n",
    "plt.xlabel(\"Category\", fontsize=14)\n",
    "plt.ylabel(\"Count\", fontsize=14)\n",
    "plt.show()\n",
    "random_samples = []\n",
    "\n",
    "# Get samples fom each category \n",
    "for category in fl_count.index:\n",
    "    samples = flowers['image'][flowers['category'] == category].sample(4).values\n",
    "    for sample in samples:\n",
    "        random_samples.append(sample)\n",
    "\n",
    "\n",
    "\n",
    "# Plot the samples\n",
    "f, ax = plt.subplots(5,4, figsize=(15,10))\n",
    "for i,sample in enumerate(random_samples):\n",
    "    ax[i//4, i%4].imshow(mimg.imread(random_samples[i]))\n",
    "    ax[i//4, i%4].axis('off')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5b0ac4d595f4d91c3a0fa2c1e317fa7b3fb44f97",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%mkdir -p data/train\n",
    "%mkdir -p data/valid\n",
    "\n",
    "# Inside the train and validation sub=directories, make sub-directories for each catgeory\n",
    "%cd data\n",
    "%mkdir -p train/daisy\n",
    "%mkdir -p train/tulip\n",
    "%mkdir -p train/sunflower\n",
    "%mkdir -p train/rose\n",
    "%mkdir -p train/dandelion\n",
    "\n",
    "%mkdir -p valid/daisy\n",
    "%mkdir -p valid/tulip\n",
    "%mkdir -p valid/sunflower\n",
    "%mkdir -p valid/rose\n",
    "%mkdir -p valid/dandelion\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "79f4c22192e4a31d3b79b33d76ed8bbc2133848e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for category in fl_count.index:\n",
    "    samples = flowers['image'][flowers['category'] == category].values\n",
    "    perm = np.random.permutation(samples)\n",
    "    # Copy first 30 samples to the validation directory and rest to the train directory\n",
    "    for i in range(30):\n",
    "        name = perm[i].split('/')[-1]\n",
    "        shutil.copyfile(perm[i],'./data/valid/' + str(category) + '/'+ name)\n",
    "    for i in range(31,len(perm)):\n",
    "        name = perm[i].split('/')[-1]\n",
    "        shutil.copyfile(perm[i],'./data/train/' + str(category) + '/' + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3a507cde115817fd219cfc1414ad438ff5b8d993",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')  # more than two classes\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/valid',\n",
    "        target_size=(150,150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "98c7b9e2a7bc2a2cdc2b9317046f711b2a554eab",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    # Get base model \n",
    "    base_model = VGG16(include_top=False, input_shape=(150,150,3))\n",
    "    # Freeze the layers in base model\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    # Get base model output \n",
    "    base_model_ouput = base_model.output\n",
    "    \n",
    "    # Add new layers\n",
    "    x = Flatten()(base_model.output)\n",
    "    x = Dense(500, activation='relu', name='fc1')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(5, activation='softmax', name='fc2')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e5018a19d2bf4bd83a86503a984d1ffebfb52119",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.set_learning_phase(1)\n",
    "model = get_model()\n",
    "# Compile it\n",
    "opt = Adam(lr=1e-3, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "#Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9a69a46f6352e627c7b440e6ad3935f47ef2c7b1",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=4168 // batch_size,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=150 // batch_size)\n",
    "K.set_learning_phase(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d0618373a6d9b560a2bdbb76e78bffcded616b3b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = \"\"\n",
    "        frozen_graph = convert_variables_to_constants(session, input_graph_def,\n",
    "                                                      output_names, freeze_var_names)\n",
    "        return frozen_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f4514e1074a5ab5b3e70339bc5302124a9e9831d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "frozen_graph = freeze_session(K.get_session(),\n",
    "                              output_names=[out.op.name for out in model.outputs])\n",
    "tf.train.write_graph(frozen_graph, \"\", \"similar.pb\", as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f17a8ba17538db1ad3dcb1c5c290ea797ec5df06",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%rm -r data/*\n",
    "%rmdir data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
